{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import webbrowser\n",
    "from random import shuffle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_input = 10222\n",
    "num_classes = 120 \n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "display_step = 20\n",
    "dropout = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, None])\n",
    "Y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases, dropout):\n",
    "    x = tf.reshape(x, shape=[-1, 100, 100, 3])\n",
    "\n",
    "    \n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'])\n",
    "    conv3 = maxpool2d(conv3, k=2)\n",
    "\n",
    "    conv4 = conv2d(conv3, weights['wc4'], biases['bc4'])\n",
    "    conv4 = maxpool2d(conv4, k=2)\n",
    "\n",
    "    print conv4\n",
    "    print weights['wd1'].get_shape().as_list()[0]\n",
    "    fc1 = tf.reshape(conv4, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "    print(fc1)\n",
    "    # Output, class prediction\n",
    "    mat_mul = tf.matmul(fc1, weights['out'])\n",
    "    print(mat_mul)\n",
    "    out = tf.add(mat_mul, biases['out'])\n",
    "    print(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 3, 4])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 4, 8])),\n",
    "    'wc3': tf.Variable(tf.random_normal([5, 5, 8, 16])),\n",
    "    'wc4': tf.Variable(tf.random_normal([5, 5, 16, 32])),\n",
    "\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*32, 600])),\n",
    "    'out': tf.Variable(tf.random_normal([600, num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([4])),\n",
    "    'bc2': tf.Variable(tf.random_normal([8])),\n",
    "    'bc3': tf.Variable(tf.random_normal([16])),\n",
    "    'bc4': tf.Variable(tf.random_normal([32])),\n",
    "    'bd1': tf.Variable(tf.random_normal([600])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_3:0\", shape=(?, 7, 7, 32), dtype=float32)\n",
      "1568\n",
      "Tensor(\"dropout/mul:0\", shape=(?, 600), dtype=float32)\n",
      "Tensor(\"MatMul_1:0\", shape=(?, 120), dtype=float32)\n",
      "Tensor(\"Add_1:0\", shape=(?, 120), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "logits = conv_net(X, weights, biases, keep_prob)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder  = '/home/bhawani/Desktop/Practice/Capstone_problem/train'\n",
    "images_list = os.listdir(folder)\n",
    "shuffle(images_list)\n",
    "train_images = images_list[:9500]\n",
    "test_images = images_list[9500:]\n",
    "labels_df = pd.read_csv('labels.csv')\n",
    "labels_df = pd.concat([labels_df,pd.get_dummies(labels_df['breed'], prefix='breed')],axis=1)\n",
    "labels_df = labels_df.drop(['breed'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resized(img):\n",
    "    return cv2.resize(img,(100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hsv(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch(images_list,labels,step,batch_size):\n",
    "    images_array = list()\n",
    "    y_array = list()\n",
    "    for i in range((step-1)*batch_size,(step)*batch_size):\n",
    "        img = cv2.imread(folder+'/'+images_list[i])\n",
    "        images_array.append(resized(hsv(img)).flatten())\n",
    "        y = np.array(labels[labels.id == images_list[i][:-4]])\n",
    "        y = np.delete(y, [0])\n",
    "        y_array.append(y)\n",
    "    return np.array(images_array).T,np.array(y_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.summary.scalar('accuracy',accuracy)\n",
    "tf.summary.scalar('loss',loss_op)\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter('/home/bhawani/Desktop/Practice/Capstone_problem/checkpoints_3rd', tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n",
      "Step 1, Minibatch Loss= 1147232640.000000, Training Accuracy= 0.03125\n",
      "Step 20, Minibatch Loss= 394901376.000000, Training Accuracy= 0.00000\n",
      "Step 40, Minibatch Loss= 285375296.000000, Training Accuracy= 0.00000\n",
      "Step 60, Minibatch Loss= 215207744.000000, Training Accuracy= 0.04688\n",
      "Step 80, Minibatch Loss= 211705584.000000, Training Accuracy= 0.00000\n",
      "Step 100, Minibatch Loss= 159937120.000000, Training Accuracy= 0.00000\n",
      "Step 120, Minibatch Loss= 164702624.000000, Training Accuracy= 0.00000\n",
      "Step 140, Minibatch Loss= 138526576.000000, Training Accuracy= 0.00000\n",
      "('Validation Accuracy of 0:', 0.005540166)\n",
      "Step 1, Minibatch Loss= 126501088.000000, Training Accuracy= 0.01562\n",
      "Step 20, Minibatch Loss= 100003776.000000, Training Accuracy= 0.00000\n",
      "Step 40, Minibatch Loss= 81105136.000000, Training Accuracy= 0.00000\n",
      "Step 60, Minibatch Loss= 76561680.000000, Training Accuracy= 0.00000\n",
      "Step 80, Minibatch Loss= 67811248.000000, Training Accuracy= 0.00000\n",
      "Step 100, Minibatch Loss= 53621528.000000, Training Accuracy= 0.00000\n",
      "Step 120, Minibatch Loss= 46623616.000000, Training Accuracy= 0.01562\n",
      "Step 140, Minibatch Loss= 37995236.000000, Training Accuracy= 0.00000\n",
      "('Validation Accuracy of 1:', 0.0069252076)\n",
      "Step 1, Minibatch Loss= 30687752.000000, Training Accuracy= 0.00000\n",
      "Step 20, Minibatch Loss= 21994814.000000, Training Accuracy= 0.00000\n",
      "Step 40, Minibatch Loss= 17027818.000000, Training Accuracy= 0.01562\n",
      "Step 60, Minibatch Loss= 13768687.000000, Training Accuracy= 0.00000\n",
      "Step 80, Minibatch Loss= 11865298.000000, Training Accuracy= 0.03125\n",
      "Step 100, Minibatch Loss= 8705714.000000, Training Accuracy= 0.01562\n",
      "Step 120, Minibatch Loss= 8115243.000000, Training Accuracy= 0.00000\n",
      "Step 140, Minibatch Loss= 5596638.000000, Training Accuracy= 0.00000\n",
      "('Validation Accuracy of 2:', 0.011080332)\n",
      "Step 1, Minibatch Loss= 5190410.000000, Training Accuracy= 0.00000\n",
      "Step 20, Minibatch Loss= 3754131.500000, Training Accuracy= 0.00000\n",
      "Step 40, Minibatch Loss= 2521121.250000, Training Accuracy= 0.03125\n",
      "Step 60, Minibatch Loss= 1699425.000000, Training Accuracy= 0.00000\n",
      "Step 80, Minibatch Loss= 2638490.500000, Training Accuracy= 0.00000\n",
      "Step 100, Minibatch Loss= 1129427.875000, Training Accuracy= 0.00000\n",
      "Step 120, Minibatch Loss= 1157678.625000, Training Accuracy= 0.00000\n",
      "Step 140, Minibatch Loss= 823567.062500, Training Accuracy= 0.00000\n",
      "('Validation Accuracy of 3:', 0.015235457)\n",
      "Step 1, Minibatch Loss= 654394.500000, Training Accuracy= 0.00000\n",
      "Step 20, Minibatch Loss= 685327.375000, Training Accuracy= 0.01562\n",
      "Step 40, Minibatch Loss= 299380.250000, Training Accuracy= 0.00000\n",
      "Step 60, Minibatch Loss= 215475.562500, Training Accuracy= 0.00000\n",
      "Step 80, Minibatch Loss= 814102.875000, Training Accuracy= 0.01562\n",
      "Step 100, Minibatch Loss= 189313.468750, Training Accuracy= 0.00000\n",
      "Step 120, Minibatch Loss= 256641.593750, Training Accuracy= 0.01562\n",
      "Step 140, Minibatch Loss= 211446.781250, Training Accuracy= 0.00000\n",
      "('Validation Accuracy of 4:', 0.008310249)\n",
      "Step 1, Minibatch Loss= 92125.976562, Training Accuracy= 0.00000\n",
      "Step 20, Minibatch Loss= 195996.500000, Training Accuracy= 0.01562\n",
      "Step 40, Minibatch Loss= 87072.242188, Training Accuracy= 0.00000\n",
      "Step 60, Minibatch Loss= 24999.132812, Training Accuracy= 0.00000\n",
      "Step 80, Minibatch Loss= 377097.437500, Training Accuracy= 0.01562\n",
      "Step 100, Minibatch Loss= 80408.257812, Training Accuracy= 0.00000\n",
      "Step 120, Minibatch Loss= 62060.890625, Training Accuracy= 0.01562\n",
      "Step 140, Minibatch Loss= 90104.046875, Training Accuracy= 0.00000\n",
      "('Validation Accuracy of 5:', 0.008310249)\n",
      "Step 1, Minibatch Loss= 34895.925781, Training Accuracy= 0.00000\n",
      "Step 20, Minibatch Loss= 42872.023438, Training Accuracy= 0.01562\n",
      "Step 40, Minibatch Loss= 25518.337891, Training Accuracy= 0.00000\n",
      "Step 60, Minibatch Loss= 14738.923828, Training Accuracy= 0.00000\n",
      "Step 80, Minibatch Loss= 190631.312500, Training Accuracy= 0.01562\n",
      "Step 100, Minibatch Loss= 27403.015625, Training Accuracy= 0.00000\n",
      "Step 120, Minibatch Loss= 94.630020, Training Accuracy= 0.01562\n",
      "Step 140, Minibatch Loss= 31904.683594, Training Accuracy= 0.00000\n",
      "('Validation Accuracy of 6:', 0.0069252076)\n",
      "Step 1, Minibatch Loss= 10791.761719, Training Accuracy= 0.00000\n",
      "Step 20, Minibatch Loss= 2344.027344, Training Accuracy= 0.01562\n",
      "Step 40, Minibatch Loss= 20245.878906, Training Accuracy= 0.00000\n",
      "Step 60, Minibatch Loss= 6690.168457, Training Accuracy= 0.00000\n",
      "Step 80, Minibatch Loss= 74154.601562, Training Accuracy= 0.01562\n",
      "Step 100, Minibatch Loss= 9125.669922, Training Accuracy= 0.00000\n",
      "Step 120, Minibatch Loss= 5.078585, Training Accuracy= 0.01562\n",
      "Step 140, Minibatch Loss= 7663.866699, Training Accuracy= 0.00000\n",
      "('Validation Accuracy of 7:', 0.0069252076)\n",
      "Step 1, Minibatch Loss= 7706.634766, Training Accuracy= 0.00000\n",
      "Step 20, Minibatch Loss= 5.023907, Training Accuracy= 0.01562\n",
      "Step 40, Minibatch Loss= 11169.546875, Training Accuracy= 0.00000\n",
      "Step 60, Minibatch Loss= 4274.721191, Training Accuracy= 0.00000\n",
      "Step 80, Minibatch Loss= 22310.380859, Training Accuracy= 0.01562\n",
      "Step 100, Minibatch Loss= 5.003714, Training Accuracy= 0.00000\n",
      "Step 120, Minibatch Loss= 5.044426, Training Accuracy= 0.01562\n",
      "Step 140, Minibatch Loss= 4.944775, Training Accuracy= 0.00000\n",
      "('Validation Accuracy of 8:', 0.0069252076)\n",
      "Step 1, Minibatch Loss= 3875.562012, Training Accuracy= 0.00000\n",
      "Step 20, Minibatch Loss= 4.993894, Training Accuracy= 0.01562\n",
      "Step 40, Minibatch Loss= 4839.707520, Training Accuracy= 0.00000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a8ff198a7de3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;31m# Run optimization op (backprop)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-561c70ab36a2>\u001b[0m in \u001b[0;36mnext_batch\u001b[0;34m(images_list, labels, step, batch_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimages_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mimages_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mimages_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs=15\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    num_steps = int(len(train_images)/batch_size)\n",
    "    print(num_steps)\n",
    "    for e in range(epochs):\n",
    "        for step in range(1, num_steps+1):\n",
    "            batch_x, batch_y = next_batch(train_images,labels_df,step,batch_size)\n",
    "            sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, keep_prob: 0.8})\n",
    "            if step % display_step == 0 or step == 1:\n",
    "                loss, acc ,summary = sess.run([loss_op, accuracy,merged], feed_dict={X: batch_x,\n",
    "                                                                     Y: batch_y,\n",
    "                                                                     keep_prob: 1.0})\n",
    "                \n",
    "                print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(acc))\n",
    "                save_path = saver.save(sess, \"/home/bhawani/Desktop/Practice/Capstone_problem/checkpoints_3rd/model_\"+str(e)+'_'+str(step)+\".ckpt\")\n",
    "        \n",
    "        test_array = list()\n",
    "        y_array = list()\n",
    "        for i in range(len(test_images)):\n",
    "            img = cv2.imread(folder+'/'+test_images[i])\n",
    "            test_array.append(resized(img).flatten())\n",
    "            y = np.array(labels_df[labels_df.id == test_images[i][:-4]])\n",
    "            y = np.delete(y,[0])\n",
    "            y_array.append(y)\n",
    "        print(\"Validation Accuracy of \"+str(e)+':', sess.run(accuracy, feed_dict={X: np.array(test_array).T,Y: np.array(y_array),keep_prob: 1.0}))\n",
    "    writer.add_summary(summary,step)\n",
    "    print(\"Optimization Finished!\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/bhawani/Desktop/Practice/Capstone_problem/checkpoints_3rd/model_12_140.ckpt\n",
      "[  0 115   0   0   0   0   0   0   0   0   0   0   0   0   0 111   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0 111   0   0   0   0   0  43\n",
      "   0  10   0   0 109  10   0   0   0  10   0   0   0  32   0   0  46  18\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0 110   0   0   0\n",
      "   0   0   0   0   0   0   0   0 105   0   0   0  54   0   0   0   0   0\n",
      "   0   0  54   0   0   0  56   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  43   0   0   0   0   0   0   0   0  42   0   0   0   0\n",
      "   0   0   0   0  44   0   0   0   0   0   0   0   0   0   0   0  11   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0 110   0   0   0\n",
      "  69   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  15   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0 110   0   0   0 110   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  75   0   0   0   0\n",
      "   0   0   0   0   0  19  31   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  93   0   0   0   0   0   0   0 105  93   0   0   0   0   0 107   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      " 107   0   0   0   0   0   0   0  67   0   0   0  57   0   0   0   0   0\n",
      "   0   0   0   0   0   0 110   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0]\n",
      "[110  52  13  89  33  99  89  61 111 101  85  81  21  42 105  68  23  84\n",
      "  64  95 113  25  31   6  67  85  26  31  33  56  58  40  65   4  81  53\n",
      "   9  71  45  67  86  96  85  52  94  54  24  70  72  32  67  94  33 108\n",
      " 103  16 107  27 102  14  10   0  12  96  18 118  15  59  73  27  78 104\n",
      "  73   5  59 100   1 100  16  55  73  67  83  60  64   8  43  86  31  13\n",
      "  38  35 112 104  94  84  55  50 116 103  19  17  26  11  16  10  72  91\n",
      "  84 110  92  43  48  37  58  43  20   6  56  31   7  68  94  97  29  47\n",
      "  10   2  96 117  46 119 101 110  95  67  40  14  75  91  57  64  89  14\n",
      "  25  61  42 102  66   1   6   7  52  42  22   2  68  75  50  11   4  37\n",
      "  18  95  41  12  34  47  37  62 100  10  15   3  36  79  33   8  24   2\n",
      " 105  96  56  84  26   2  48 114  59  72  40  71   7  90  56 113  77  94\n",
      "  35   1  99  97  84 102  98 101  25  58  81  46  76 109 100  79 107  69\n",
      "  26  73  93 112  97  19 114  95  71  68  79  23  67  61  93   1 112  20\n",
      "  27  28  92  16   4 100  75 106  49  11  75  42  66  16  48  82 104   7\n",
      "  44  47  54  28  42  34  33  48  97 111  14  60  13  31  14  44 117  54\n",
      " 105  79   6 119  73   4  51  52  13  71  94  98  14  29  97  81  87  81\n",
      "  10  33  18  86  74  80  54  44   4  24  13  68  44  49  36  35  35  81\n",
      "  39 106  73  28   7  13   4  61  38  10 116  54  26  23 102  57  32  17\n",
      "  29 114  69  87  18  93  44 105  72  59  27  32  95  95  81   7  37  76\n",
      "  37  34  63  39 113  55   6  46  34 112  42  94  88  60  66  84  70  26\n",
      "  82  59 117  57  21  89  62  80  61  48  67  81  62  12 115   3  65   1\n",
      "  28  61  82  26  67 115  69  94  64  85  53  40  11  94   8  84  40  64\n",
      "  76 111  69   5]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"/home/bhawani/Desktop/Practice/Capstone_problem/checkpoints_3rd/model_12_140.ckpt\")\n",
    "    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    test_array = list()\n",
    "    y_array = list()\n",
    "    for i in range(400):\n",
    "            img = cv2.imread(folder+'/'+train_images[i])\n",
    "            test_array.append(resized(img).flatten())\n",
    "            y = np.array(labels_df[labels_df.id == train_images[i][:-4]])\n",
    "            y = np.delete(y,[0])\n",
    "            y_array.append(y)\n",
    "    predictions = sess.run(prediction, feed_dict={X: np.array(test_array).T,Y: np.array(y_array),keep_prob: 1.0})\n",
    "    print np.argmax(predictions, 1)\n",
    "    print np.argmax(np.array(y_array),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
